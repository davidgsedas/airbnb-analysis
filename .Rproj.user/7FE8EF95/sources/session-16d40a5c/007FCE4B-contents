---
title: "Airbnb - Revenue Management"
author: "David Gómez Sedas"
format: pdf
editor: visual
---

A continuación se enumeran todas las librerías utilizadas en el AB:

```{r}
library(tidyverse)
library(tidymodels)
library(quarto)
library(fastDummies)
library(GGally)
library(factoextra)
```

# Datos usados

```{r}
df <- read_csv("listings_bcn.csv", show_col_types = FALSE)
```

## Origen de los datos

Los datos han sido extraidos de "Inside Airbnb", el cual es un proyecto que provee datos e información sobre el impacto que tiene Airbnb sobre las comunidades residenciales.

La finalidad de este proyecto es trabajar en torno a una visión que consiste en informar a estas comunidades sobre el uso real de airbnb.

Los datos son extraidos de la web de Airbnb oficial y son almacenados en archivos compatibles con datos tabulares para distribuirlos. Podemos encontrar que los datos están separados por ciudades y estos se suelen actualizar frecuentemente para mostrar una imagen lo mas actual posible.

Todos los datos de la web estan licenciados bajo Creative Commons Attribution 4.0 International License.

Concretamente, los datos utilizados en este trabajo consisten en todas las residencias activas en Airbnb de la ciudad de Barcelona. En ellas podemos encontar diferentes tipos de servicios: Apartamentos, casas, habitaciones y camas en habitaciones compartidas.

## Contenido

Los datos utilizados consisten en unos datos tabulares los cuales consisten en 18086 entradas y 75 columnas.

```{r}
str(df)
```

En el archivo encontramos cuatro tipos de datos distintos:

-   double

-   character

-   logical

-   date

Los datos nos hablan de todos los apartados relacionados con el alojamiento ofrecido, la información del host, el precio medio, la disponibilidad, imagenes de los alojamientos e información de las reseñas.

## Definición de variables

Vamos a definir las variables que contienen los datos

|                              |                                                                                                       |
|------------------------------|-------------------------------------------------------------------------------------------------------|
| id                           | Identificador único del alojamiento en Airbnb                                                         |
| listing_url                  | Link al portal del alojamiento                                                                        |
| scrape_id                    | Identificador de scrapping de los datos                                                               |
| last_scraped                 | Hora del scrapping                                                                                    |
| source                       | Fuente, de la entrada, si es reciente o antigua.                                                      |
| name                         | Nombre del alojamiento                                                                                |
| description                  | Descripción del alojamiento                                                                           |
| neighborhood_overview        | Descripción del barrio del host                                                                       |
| picture_url                  | Link de las fotografías del alojamiento                                                               |
| host_id                      | Identificador del host del alojamiento                                                                |
| host_url                     | Link al portal del perfil del host                                                                    |
| host_name                    | Nombre del host                                                                                       |
| host_since                   | Fecha de registro como host                                                                           |
| host_location                | Localización del host                                                                                 |
| host_about                   | Descripción del host sobre si mismo.                                                                  |
| host_response_time           | Tiempo promedio de respuesta del host                                                                 |
| host_response_rate           | Porcentaje de respuestas realizadas por el host.                                                      |
| host_acceptance_rate         | Porcentaje de solicitudes de alojamiento aceptadas por el host.                                       |
| host_is_superhost            | Estatus otorgado por Airbnb por ser un host con ciertas características positivas según la plataforma |
| host_picture_url             | Link de la foto de perfil del host                                                                    |
| host_neighbourhood           | Barrio donde reside el host                                                                           |
| host_listings_count          | Número de alojamientos listados por el host (cuenta manual)                                           |
| host_total_listings_count    | Número de alojamientos listados por el host (cuenta segun Airbnb)                                     |
| host_verifications           | Métodos por los cuales el host se ha verificado                                                       |
| host_has_profile_pic         | Boolean que indica si el host se ha verificado                                                        |
| host_identity_verified       | Boolean que indica si la identidad se ha verificado                                                   |
| neighbourhood_group_cleansed | Barrio según coordenadas.                                                                             |
| latitude                     | Coordenada de latitud del alojamiento                                                                 |
| longitude                    | Coordenada de longitud del alojamiento                                                                |
| property_type                | Tipo de propiedad del alojamiento                                                                     |
| room_type                    | Tipo de habitación, si es compartida o individual.                                                    |
| accommodates                 | Capacidad de personas                                                                                 |
| bathrooms                    | Número de banos                                                                                       |
| bedrooms                     | Número de dormitorios                                                                                 |
| beds                         | Número de camas                                                                                       |
| price                        | Precio diario para alojarse                                                                           |
| minimum_nights               | Noches mínimas que hay alojarse para reservar                                                         |
| maximum_nights               | Noches máximas que se pueden reservar                                                                 |
| has_availability             | Indica si hay disponibilidad.                                                                         |
| availability_30              | Disponibilidad en los proximos 30 dias.                                                               |
| availability_60              | Disponibilidad en los proximos 60 dias.                                                               |
| availability_90              | Disponibilidad en los proximos 90 dias.                                                               |
| availability_365             | Disponibilidad en los proximos 365 dias.                                                              |
| number_of_reviews            | Número de reviews que ha recibido el alojamiento.                                                     |
| number_of_reviews_ltm        | Número de reviews que ha recibido el alojamiento en los últimos 12 meses.                             |
| number_of_reviews_l30d       | Número de reviews que ha recibido el alojamiento en los últimos 30 dias.                              |
| first_review                 | Fecha de la primera review del alojamiento.                                                           |
| last_review                  | Fecha de la última review del alojamiento                                                             |
| review_scores_rating         | Nota media de las reviews en general                                                                  |
| review_scores_accuracy       | Nota media de las reviews en precisión                                                                |
| review_scores_cleanliness    | Nota media de las reviews en limpieza                                                                 |
| review_scores_checkin        | Nota media de las reviews en el proceso de checkin                                                    |
| review_scores_communication  | Nota media de las reviews en comunicación                                                             |
| review_scores_location       | Nota media de las reviews en localización                                                             |
| review_scores_value          | Nota media de las reviews en valor (calidad / precio)                                                 |
| license                      | Licencia del alojamiento                                                                              |
| instant_bookable             | Indica si el alojamiento se reserva automáticamente o se necesita la aprobación del host.             |

## Muestra de los datos

A continuación, una muestra de los datos obtenidos:

```{r}
head(df)
```

Vamos a ver un análisis rápido de los datos:

```{r}
summary(df)
```

# Objetivo del proyecto

El objetivo con el análisis de datos es crear un modelo el cual enseñe a actuales o futuros propietarios de alojamientos de airbnb a obtener los máximos ingresos posibles teniendo en cuenta todas las características en del alojamiento y su perfil en Airbnb.

La variable a predecir es "price", la cual es el precio de reservar cada alojamiento en su fecha de disponiblidad mas reciente.

El modelo ideal será en el que haya menos residuo entre los valores reales y los valores predichos.

## Modelo escogido

El modelo escogido es una regresión lineal, que es de aprendizaje supervisado y continuo. Hemos tenido en cuenta otros posibles modelos y hemos llegado a las siguientes conclusiones:

+------------------+-----------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| Modelo           | Pros                                                                                    | Contras                                                                                 |
+==================+=========================================================================================+=========================================================================================+
| Regresión lineal | -   Es simple y fácil de entender, los resultados pueden ser visualizados rapidamente.  | -   Se basa en supuestos estrictos que muchas veces no se cumplen en datos reales.      |
|                  |                                                                                         |                                                                                         |
|                  | -   Los coeficientes de regresión pueden interpretarse directamente.                    | -   Es sensible a valores atípicos.                                                     |
+------------------+-----------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| Regresión Ridge  | -   Controla el sobreajuste, penalizando a los coeficientes grandes.                    | -   No realiza selección de variables, todos los predictores se mantienen en el modelo. |
|                  |                                                                                         |                                                                                         |
|                  | -   Menos sensible a valores atípicos.                                                  | -   Requiere la selección del parámetros de regularización.                             |
+------------------+-----------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| Regresión Lasso  | -   Es capaz de realizar selección de variables reduciendo algunos coeficientes a cero. | -   Puede ser inestable en la presencia de predictores altamente correlacionados.       |
|                  |                                                                                         |                                                                                         |
|                  | -   Útil cuando se tienen muchas variables y se desea simplificar el modelo.            | -   También requiere la selección cuidadosa del parámetro de regularización.            |
+------------------+-----------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+

## Programa y paquetes seleccionados: Decisión y razones

R es un lenguaje de programación muy utilizado en estadística y aprendizaje automático debido a su gran cantidad de paquetes y funciones para análisis de datos y modelado estadístico. Su popularidad entre los estadísticos y científicos de datos se debe a la facilidad con la que se pueden manipular datos, realizar cálculos estadísticos y generar gráficos avanzados. Para esta funcionalidad concreta, en los ultimos años, han destacado dos grupos de liberías que también vamos a utilizar en nuestro modelo, como son Tidyverse y Tidymodels.

El tidyverse es una colección de paquetes de R diseñados para la ciencia de datos que comparten una filosofía subyacente de diseño y gramática. Algunos de los paquetes más destacados del tidyverse incluyen:

-   dplyr y tidyr para la manipulación de datos.

-   Ggplot para la creación de visualizaciones avanzadas.

Tidymodels tiene el objetivo de proporcionar una gramática coherente y fácil de usar para la modelización predictiva en R. Algunos paquetes son:

-   rsample que contiene funciones para la separación de sets de un dataframe

-   yardstick: Incluye métricas para medir el rendimiento de los modelos.

Ambos grupos de librerias tienen finalidades similares como el uso de una grámatica consistente, el formato con pipes y en general que sea legible y simple.

# Limpieza de datos

En primer lugar vamos a eliminar aquellas variables que contienen datos que no vamos a utilizar por alguno de los siguientes motivos:

-   Corresponden a links de cada una de las entradas

-   Id's de elementos concretos que no vamos a utilizar

-   Descripciones y otros elementos strings

-   Variables cubiertas por otras las cuales estandarizan el formato

```{r}
df <- df |>
  select(c(id,
           host_id,
           host_since,
           host_response_time,
           host_response_rate,
           host_acceptance_rate,
           host_is_superhost,
           host_verifications,
           host_has_profile_pic,
           host_identity_verified,
           calculated_host_listings_count,
           calculated_host_listings_count_entire_homes,
           calculated_host_listings_count_private_rooms,
           calculated_host_listings_count_shared_rooms,
           neighbourhood_group_cleansed,
           latitude,
           longitude,
           room_type,
           accommodates,
           bathrooms_text,
           bedrooms,
           beds,
           price,
           minimum_nights,
           maximum_nights,
           has_availability,
           availability_30,
           availability_60,
           availability_90,
           availability_365,
           instant_bookable,
           number_of_reviews,
           number_of_reviews_l30d,
           review_scores_rating,
           review_scores_accuracy,
           review_scores_cleanliness,
           review_scores_checkin,
           review_scores_communication,
           review_scores_location,
           review_scores_value,
           ))
```

## Ajustes de formato

**host_response_time**

Nos encontramos con variables categoricas en diferentes medidas de tiempo. Sería conveniente ajustar todas estas pora que estén en la misma medida de tiempo.

```{r}
unique(df$host_response_time)
```

Encontramos seis valores. A continuación listamos las diferentes categorías y su nuevo valor: - "within an hour" -\> \<1h - "within a few hours" -\> \~12h - "within a day -\> \<24h -"a few days or more" -\> \>48h - "N/A" -\> Unificar con NA

```{r}
df$host_response_time <- ifelse(df$host_response_time == "within an hour", "<1h",
                        ifelse(df$host_response_time == "within a few hours", "~12h",
                        ifelse(df$host_response_time == "within a day", "~24h",
                        ifelse(df$host_response_time == "a few days or more", ">48h",
                        ifelse(df$host_response_time == "N/A", NA, df$host_response_time)))))
```

**bathrooms_text**

Esta variable incluye el valor númerico de baños y además nos indica si estos son compartidos o no. Para la claridad en los datos sería conveniente crear dos variables de esta:

1.  Una variable número con el número de baños.

2.  Un Boolean indicando si estos son compartidos o no.

```{r}
unique(df$bathrooms_text)
```

Vemos que casi todas las categorías tienen números. A excepción de tres de ellas. Vamos a añadirselo para compartir la estructura:

```{r}
df$bathrooms_text <- ifelse(df$bathrooms_text == "Shared half-bath", "0.5 Shared bath",
                            ifelse(df$bathrooms_text == "Private half-bath", "0.5 bath",
                            ifelse(df$bathrooms_text == "Half-bath", "0.5 bath", df$bathrooms_text)))

```

A continuación creamos la columna boolean la cual nos indica si un baño es compartido o no (Asumimos que si no es indicado, es privado).

```{r}
df$shared_bathrooms <- grepl("shared|Shared", df$bathrooms_text)
```

Seguidamente creamos una nueva columna que extraiga el número de baños del valor bathrooms_text

```{r}
df$n_bathrooms <- sapply(strsplit(df$bathrooms_text, " "), function(x) as.numeric(x[1]))
```

Recolocamos las columnas en la posición de bathrooms_text y eliminamos esta.

```{r}
bathrooms_text_position <- which(colnames(df) == "bathrooms_text")

df <- df %>%
  relocate(all_of(c("n_bathrooms", "shared_bathrooms")), .before = bathrooms_text_position)


df <- df %>%
  select(-bathrooms_text)

rm(bathrooms_text_position)
```

**host_verifications**

En esta variable podemos ver en formato lista, los medios por los cuales se ha verificado un host. Para que los datos sean mas accesibles podemos crear una variable de tipo boolean por cada tipo de medio posible de verificación.

```{r}
unique(df$host_verifications)
```

Encontramos tres tipos de verificación:

-   "email"

-   "phone"

-   "work_email"

Creamos las tres variables y añadimos true si ese método está incluido en la columna host_verifications.

```{r}
df <- df %>%
  mutate(verification_email = str_detect(df$host_verifications, "email"),
         verification_phone = str_detect(df$host_verifications, "phone"),
         verification_work_email = str_detect(df$host_verifications, "work_email"))

host_verification_text_position <- which(colnames(df) == "host_verifications")

df <- df %>%
  relocate(all_of(c("verification_email", "verification_phone", "verification_work_email")), .before = host_verification_text_position)

df <- df %>%
  select(-host_verifications)

rm(host_verification_text_position)
```

**price**

Podemos convertir price en una variable numérica para poderla usar en visualizaciones y otros tipos de funciones de tipo continuo:

```{r}
df$price <- as.numeric(gsub("\\$", "", df$price))
```

**review_score_rating**

El valor mínimo que puede tener un alojamiento es 1. En algunos campos pone 0 a causa de que el resto de valores son NA. Vamos a modificar estos valores a NA.

```{r}
df$review_scores_rating <- ifelse(df$review_scores_rating == 0, NA, df$review_scores_rating)
```

**host_response_rate y host_acceptance_rate**

Cambiamos ambas variables de tipo character con porcentaje a tipo numérico double:

```{r}
df$host_response_rate <- as.numeric(sub("%", "", df$host_response_rate))/100
df$host_acceptance_rate <- as.numeric(sub("%", "", df$host_acceptance_rate))/100
```

**Conversión de campos con tags en factores**

Cambiamos todas las columnas de tipos strings que tengan etiquetas a tipo factor para que su uso sea mas sencillo.

```{r}
df <- df %>%
  mutate(
    host_response_time = factor(host_response_time),
    neighbourhood_group_cleansed = factor(neighbourhood_group_cleansed),
    room_type = factor(room_type)
  )
```

## Tratamiento de NA's

Comprobamos cuantos NA's faltan en cada columna para ver que tratamiento hacer con ellos.

```{r}
na_analysis <- df %>% summarize(across(everything(), ~sum(is.na(.))))
na_analysis
```

**Columnas numéricas**

En primer lugar vamos a promediar todas las columnas númericas:

```{r}
df <- df |>
  mutate(across(where(is.numeric), ~if (any(is.na(.))) floor(replace_na(., mean(., na.rm = TRUE))) else .))
```

**host_response_time**

Vamos a hacer una tablaq para ver la distribución de cada categoría:

```{r}
frecuencias_host_response_time <- table(df$host_response_time)
porcentajes_host_response_time <- prop.table(frecuencias_host_response_time) * 100
print(porcentajes_host_response_time)
```

Vemos como la gran mayoría responde en menos de una hora, al no ser un componente mayor esta variable vamos a justar los NA's como menores de una hora.

```{r}
df$host_response_time[is.na(df$host_response_time)] <- "<1h"
```

**host_is_superhost**

Como no tenemos información asumimos que los valores NA son false

```{r}
df$host_is_superhost[is.na(df$host_is_superhost)] <- FALSE
```

**host_has_profile_pic**

Hacemos la misma gestión en este caso

```{r}
df$host_has_profile_pic[is.na(df$host_has_profile_pic)] <- FALSE
```

**host_identity_verified**

Volvemos a convertir los valores NA que tenemos en FALSE

```{r}
df$host_identity_verified[is.na(df$host_identity_verified)] <- FALSE
```

**host_since**

Vamos a usar el valor promedio para sustituir los NA de la fecha de ingreso de los host

```{r}
mean_host_since <- mean(df$host_since, na.rm=TRUE)
df$host_since[is.na(df$host_since)] <- mean_host_since
```

# Análisis descriptivo de los datos

Vamos a hacer un análisis descriptivo de nuestros datos para poder tendencias y patrones para poder tomar decisiones sobre el modelo mas adelante.

## Summary

Vamos a ver como quedaría el summary después de haber limpiado los datos.

```{r}
summary(df)
```

## Distribución de las notas de review

```{r}
ggplot(df, aes(x = review_scores_rating)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  ggtitle("Histograma distribución de ratings") +
  xlab("Review Scores Rating") +
  ylab("Frecuencia")
```

En el gráfico podemos ver como la gran mayoría de reseñas tienen un nivel de entre 4 y 5, siendo 4 con mucha diferencia la moda. Vemos como las notas entre 1 y 3 son mínimas.

## Distribución del precio por noche

```{r}
hist(df$price, main = "Histograma distribución precio", breaks=100)
```

El rango de precios con mayor frecuencia esta entre 0 y 100, por otro lado existen pocas observaciones con precios superiores a 400. La distribución de los precios es asimétrica positiva (sesgada a la derecha), con una cola larga que se extiende hacia los precios más altos lo que implica que las frecuencias de precios disminuyen rápidamente a medida que aumenta el precio.

## Distribución entre precio y reviews

```{r}
ggplot(df, aes(price, review_scores_rating)) + 
  geom_smooth() 
```

Existe una tendencia que muestra que a medida que el precio aumenta, las calificaciones de revisión tienden a mejorar, especialmente después del punto de precio de 750. El intervalo de confianza se amplía a medida que el precio aumenta, lo que sugiere que hay más variabilidad en las calificaciones de revisión para productos o servicios más caros. La mayoría de los datos parece estar concentrada en el rango de precios más bajo.

## Media de precio por barrio

```{r}
df_precio_barrio <- df %>% select(price, neighbourhood_group_cleansed) %>% group_by(neighbourhood_group_cleansed) %>% summarize(avg_price = mean(price, na.rm = TRUE))

ggplot(df_precio_barrio, aes(reorder(neighbourhood_group_cleansed, avg_price), avg_price)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90))
```

Hay una variabilidad notable en los precios promedio entre los diferentes barrios. Eixample parece ser el barrio con el precio promedio más alto, seguido de cerca por Sarrià-Sant Gervasi. Por otro lado, Nou Barris parece ser el más económico en términos de precio promedio.

# Separación de modelo en sets

Queremos separar nuestro modelo en 3 para poder ver la efectividad de este. Usaremos un set de entrenamiento, otro de test y otro de validación. A medido que avancemos iré comprobando la efectividad del test y una vez veamos que es efectivo haremos la validación global.

Como hemos podido ver en el analisis descriptivo encontrabamos mucha diferencia de valores en *price* dependiendo del barrio en el que estuvieran situadas. Por ello, vamos a hacer una distribución proporcional de valores en cada uno de los sets.

Primer retiramos las variables id para los sets

```{r}
df <- df |>
  select(-id,
         -host_id)
```

```{r}
set.seed(123)

training_test_split <- initial_split(df, prop = 0.8, strata = neighbourhood_group_cleansed)

# Crear los data frames de entrenamiento y el resto
training_data <- training(training_test_split)
test_data <- testing(training_test_split)
rm(training_test_split)
```

# Primer modelo

Vamos a hacer una prueba con el primer modelo para ver que resultados obtenemos y como podemos mejorarlo aplicando técnicas estadísticas.

En este caso solo vamos a aplicar las variables numéricas.

```{r}
training_data1 <- training_data %>% 
  select_if(is.numeric)
```

Las aplicamos al modelo

```{r}
modelo1 <- lm(price ~ ., data = training_data1)
```

Duplicamos test_data para esta prueba

```{r}
test_data1 <- test_data
```

Predecimos con el test_data:

```{r}
predicciones_modelo1 <- predict(modelo1, newdata = test_data1)
```

Añadimos las predicciones una columna para comparar

```{r}
test_data1 <- test_data1 %>%
  mutate(predicciones = predicciones_modelo1)
```

Calcular las métricas resultantes la variable price

```{r}
metrics1 <- test_data1 %>%
  metrics(truth = price, estimate = predicciones)
```

```{r}
# Asegurarse de que 'predicciones' es un vector numérico sin nombres
test_data1$predicciones <- unname(test_data1$predicciones)
```

Calculamos el promedio de residuos y lo agregamos al data.frame de metrics

```{r}
residuo1 <- sum(residuals(modelo1))

residuo1 <- c("residuo", "standard", residuo1)

metrics1 <-rbind(metrics1, residuo1)
  
```

# **Transformación de variables en valores numéricos y estandarización**

A continuación, vamos a realizar cambios en las variables que no son de tipo numérico para poder ser incluidas en la regresión lineal:

-   Para interactuar con la fecha nos vamos a quedar simplemente con el año de ingreso en la plataforma en host_since

-   Escalamos las variables numéricas

-   Convertiremos los booleanos a numéricos

-   Usamos datos dummy para las columnas categóricas

```{r}
training_data <- training_data |>
  mutate(host_since = as.numeric(format(host_since, "%Y"))) |> 
  mutate(across(where(is.numeric), scale)) |> 
  mutate(across(where(is.logical), as.numeric))

test_data <- test_data |>
  mutate(host_since = as.numeric(format(host_since, "%Y"))) |> 
  mutate(across(where(is.numeric), scale)) |> 
  mutate(across(where(is.logical), as.numeric))

training_data <- dummy_cols(training_data, 
                         select_columns = names(which(sapply(training_data, is.factor))),
                         remove_selected_columns = TRUE)

test_data <- dummy_cols(test_data, 
                         select_columns = names(which(sapply(test_data, is.factor))),
                         remove_selected_columns = TRUE)
```

# Segundo modelo

```{r}
# En este caso solo vamos a aplicar las variables numéricas.
training_data2 <- training_data  

# Las aplicamos al modelo
modelo2 <- lm(price ~ ., data = training_data2)

# Duplicamos test_data para esta prueba
test_data2 <- test_data

# Predecimos con el test_data
predicciones_modelo2 <- predict(modelo2, newdata = test_data2)

# Añadimos las predicciones una columna para comparar
test_data2 <- test_data2 %>%
  mutate(predicciones = predicciones_modelo2)

# Calcular las métricas resultantes la variable price
metrics2 <- test_data2 %>%
  metrics(truth = price, estimate = predicciones)

# Asegurarse de que 'predicciones' es un vector numérico sin nombres
test_data2$predicciones <- unname(test_data2$predicciones)

# Calculamos el promedio de residuos y lo agregamos al data.frame de metrics
residuo2 <- sum(residuals(modelo2))

residuo2 <- c("residuo", "standard", residuo2)

metrics2 <-rbind(metrics2, residuo2)
```

# Análisis de componentes principales

Vamos a realizar el análisis de componentes principales, ya que tenemos un total de 43 variables, entonces vamos a ver cuales son las mas relevantes para nuestro modelo:

Vamos a utilizar la función pccomp para aplicar el PCA

```{r}
pca_result <- prcomp(training_data, center = TRUE, scale. = FALSE)

summary(pca_result)
```

Vamos a hacer un Scree plot para ver cual es el número de componentes principales ideal

```{r}
scree_plot <- plot(pca_result, type = "l")
```

Hacemos también un biplot para ver las variables correspondientes.

```{r}
fviz_pca_biplot(pca_result, 
                label="var")
```

Queremos visualizar las cargas de cada componente y ver que variables tienen mayor influencia.

```{r}
loadings <- pca_result$rotation

# Ver las cargas para los primeros cinco componentes principales
loadings[, 1:5]

# Convertir la matriz de cargas en un data frame
loadings_df <- as.data.frame(loadings) |>
  select(PC1, PC2, PC3, PC4, PC5)

# Sumamos los PC de cada variable
loadings_df$Suma <- rowSums(loadings_df[, c("PC1", "PC2", "PC3", "PC4", "PC5")]) 

loadings_df_sorted <- loadings_df |>
  arrange(desc(Suma))

```

El resultado es bastante sorprendente, pero tiene sentido vemos que las variables mas relevantes en primer lugar son el número de propiedades que tiene el host en si. Esto se puede deber a que a mayor número de propiedades hablamos de una dedicación profesional y conlleva un aumento de precios en sus alojamientos en general. Otras variables como el número de reviews influencia también.

Vamos a crear una lista con las variables mas relevantes, para el siguiente modelo probaremos con las variables cuya suma de componentes sea mayor que 0:

```{r}
loadings_df <- loadings_df_sorted |>
  filter(Suma > 0) 

seleccion_variables <- rownames(loadings_df)
seleccion_variables <- c(seleccion_variables, "price")
```

# Tercer modelo

Vamos a hacer un modelo solo con las variables seleccionadas:

```{r}
# En este caso solo vamos a aplicar las variables numéricas.
training_data3 <- training_data |>
  select(seleccion_variables)

# Las aplicamos al modelo
modelo3 <- lm(price ~ ., data = training_data3)

# Duplicamos test_data para esta prueba
test_data3 <- test_data |>
  select(seleccion_variables)

# Predecimos con el test_data
predicciones_modelo3 <- predict(modelo3, newdata = test_data3)

# Añadimos las predicciones una columna para comparar
test_data3 <- test_data3 %>%
  mutate(predicciones = predicciones_modelo2)

# Calcular las métricas resultantes la variable price
metrics3 <- test_data3 %>%
  metrics(truth = price, estimate = predicciones)

# Asegurarse de que 'predicciones' es un vector numérico sin nombres
test_data3$predicciones <- unname(test_data3$predicciones)

# Calculamos el promedio de residuos y lo agregamos al data.frame de metrics
residuo3 <- sum(residuals(modelo3))

residuo3 <- c("residuo", "standard", residuo3)

metrics3 <-rbind(metrics3, residuo3)
```

# Cuarto y quinto modelo

Vamos a hacer dos modelos mas: Uno con una selección mas amplia de variables y otra con una selección mas corta, al final de todo comparemos todos los modelos y sacaremos conclusiones.

## Cuarto modelo

Vamos a hacer una selección mas corta de variables filtrando por 0.10

```{r}
loadings_df <- loadings_df_sorted |>
    filter(Suma > 0.10) 

seleccion_variables <- rownames(loadings_df)
seleccion_variables <- c(seleccion_variables, "price")
```

```{r}
# En este caso solo vamos a aplicar las variables numéricas.
training_data4 <- training_data |>
  select(seleccion_variables)

# Las aplicamos al modelo
modelo4 <- lm(price ~ ., data = training_data4)

# Duplicamos test_data para esta prueba
test_data4 <- test_data |>
  select(seleccion_variables)

# Predecimos con el test_data
predicciones_modelo4 <- predict(modelo4, newdata = test_data4)

# Añadimos las predicciones una columna para comparar
test_data4 <- test_data4 %>%
  mutate(predicciones = predicciones_modelo4)

# Calcular las métricas resultantes la variable price
metrics4 <- test_data4 %>%
  metrics(truth = price, estimate = predicciones)


# Asegurarse de que 'predicciones' es un vector numérico sin nombres
test_data4$predicciones <- unname(test_data4$predicciones)

# Calculamos el promedio de residuos y lo agregamos al data.frame de metrics
residuo4 <- sum(residuals(modelo4))

residuo4 <- c("residuo", "standard", residuo4)

metrics4 <-rbind(metrics4, residuo4)
```

## Quinto modelo

Ahora haremos una selección mas larga filtrando por -0.10

```{r}
loadings_df <- loadings_df_sorted |>
    filter(Suma > -0.20) 

seleccion_variables <- rownames(loadings_df)
seleccion_variables <- c(seleccion_variables, "price")
```

```{r}
training_data5 <- training_data |>
  select(seleccion_variables)

# Las aplicamos al modelo
modelo5 <- lm(price ~ ., data = training_data5)

# Duplicamos test_data para esta prueba
test_data5 <- test_data |>
  select(seleccion_variables)

# Predecimos con el test_data
predicciones_modelo5 <- predict(modelo5, newdata = test_data5)

# Añadimos las predicciones una columna para comparar
test_data5 <- test_data5 %>%
  mutate(predicciones = predicciones_modelo5)

# Calcular las métricas resultantes la variable price
metrics5 <- test_data5 %>%
  metrics(truth = price, estimate = predicciones)

# Asegurarse de que 'predicciones' es un vector numérico sin nombres
test_data5$predicciones <- unname(test_data5$predicciones)

# Calculamos el promedio de residuos y lo agregamos al data.frame de metrics
residuo5 <- sum(residuals(modelo5))

residuo5 <- c("residuo", "standard", residuo5)

metrics5 <-rbind(metrics5, residuo5)
```

# Comparativa de modelos

Unficamos las métricas de los 5 modelos:

```{r}
metricas <- bind_rows(metrics1, metrics2, metrics3, metrics4, metrics5) |>
  select(-.estimator)
n_modelo <- rep(seq(5), each = 4)
metricas$n_modelo <- n_modelo

metricas <- metricas %>%
  pivot_wider(names_from = .metric, values_from = .estimate)

print(metricas)
```

Vamos a comentar cada modelo basándonos en las métricas proporcionadas y luego seleccionaremos el mejor modelo.

**Modelo 1**

-   El RMSE es muy alto, lo que indica que los errores de predicción son, en promedio, grandes.

-   Rsq es razonablemente alto, lo que sugiere que el modelo explica una buena cantidad de la varianza de los datos.

-   MAE es bastante alto, lo que indica errores significativos en la predicción.

-   El residuo es negativo y muy cercano a cero, lo que sugiere que en promedio, el modelo podría estar subestimando ligeramente las predicciones.

**Modelo 2**

-   El RMSE es considerablemente más bajo que el del Modelo 1, lo que indica una reducción significativa en los errores de predicción en comparación con el modelo que no utiliza normalización ni variables dummy.

-   El Rsq, es menor que el del Modelo 1. Un valor más bajo aquí sugiere que, aunque las predicciones son más precisas en términos de error cuadrático, la proporción de la varianza total que el modelo puede explicar ha disminuido.

-   El MAE reducido en el Modelo 2 refleja la mejora en la precisión de las predicciones después de la normalización y la inclusión de variables dummy. Como el MAE no da tanto peso a los errores más grandes como el

**Modelo 3**

-   El RMSE y el MAE son idénticos a los del Modelo 2, lo que indica que la selección de componentes no perjudicó la precisión de la predicción.

-   El Rsq permanece sin cambios respecto al Modelo 2, lo que sugiere que la cantidad de varianza explicada por el modelo es similar.

-   El residuo es negativo y muy pequeño, lo cual es consistente con el Modelo 2.

**Modelo 4**

-   Este modelo muestra un RMSE ligeramente más alto y un Rsq ligeramente más bajo que los Modelos 2 y 3, lo que indica que la eliminación de algunas variables mediante un umbral de carga más alto ha tenido un pequeño impacto negativo en el rendimiento del modelo.

-   El MAE es ligeramente más alto, lo que sugiere que las predicciones son menos precisas en promedio.

-   El residuo es positivo, lo que indica que este modelo podría estar sobreestimando ligeramente las predicciones en promedio.

**Modelo 5**

-   Este modelo tiene la menor RMSE y MAE de todos los modelos, lo que sugiere que tiene el mejor rendimiento en términos de precisión de la predicción.

-   El R² es también el más alto, indicando que este modelo explica la mayor parte de la varianza en los datos.

-   El residuo es negativo, pero muy cercano a cero, similar a los Modelos 2 y 3.

## Selección del modelo

El Modelo 5 parece ser el mejor en términos de todas las métricas proporcionadas. Tiene el RMSE más bajo, lo que indica que tiene el menor error de predicción promedio. También tiene el MAE más bajo, lo que sugiere que es consistente en su precisión a través de diferentes muestras. Además, el R² más alto indica que explica la mayor cantidad de varianza en la variable dependiente comparado con los otros modelos. Aunque el residuo es negativo, lo cual puede implicar una leve subestimación, está muy cerca de cero, lo que sugiere que en promedio, el sesgo del modelo es mínimo.

La inclusión de más variables (con cargas mayores de -0.10) en el Modelo 5 parece haber capturado mejor la complejidad subyacente de los datos, lo que ha resultado en un modelo más preciso.

Sin embargo, en la práctica, se recomendaría realizar una validación cruzada o pruebas en un conjunto de datos de prueba separado para evaluar mejor la capacidad del modelo para generalizar a nuevos datos antes de finalizar la selección del modelo.
